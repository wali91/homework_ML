# -*- coding: utf-8 -*-
"""homework-ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rke8Dm4edhBFTBbRpY-skTP82ZUHNjSl

# Tahapan terdiri antara lain:

1. Ubah dataset ke dalam dataframe.

2. Hapus kolom 'Id' pada dataframe serta pisahkan antara atribut dan label.

3. Bagi dataset menjadi data latih dan data uji.

4. Buat dan latih model Decision Tree.

5. Lakukan pengujian model dengan menggunakan data uji.

6. Lakukan prediksi dengan model yang telah dilatih.

7. Visualisasi model Decision Tree yang telah dilatih.
"""

import re
import pickle

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report

# Loading the dataset into a pandas dataframe
data_insurance = pd.read_csv('Prediction Insurance.csv')
pd.concat([data_insurance.head(), data_insurance.tail()])

# check data is nul
data_insurance.isnull().any()

# Printing the shape of the dataframe
print('Number of rows', data_insurance.shape[0])
print('Number of columns', data_insurance.shape[1])

# chek count Target colums name Response
data_insurance['Response'].value_counts()

# Renaming the 'Response' column to 'pay_policy'
data_insurance.rename(columns={'Response': 'pay_policy'}, inplace=True)
data_insurance['pay_policy'].value_counts()

#Let's get the data types of the different features
data_insurance.dtypes

# check for the total number of those who pay_policy and those who did not_pay_policy:
sns.countplot(x='pay_policy', data=data_insurance)

# Check for how many males and females pay_policy insurance:
sns.countplot(x='pay_policy', hue='Gender', data=data_insurance)

# check Age pay_policy insurance
sns.displot(x='Age', data=data_insurance, color='red', kde=True)

# menghilangkan kolom yang tidak penting
data_insurance.drop('id',axis=1,inplace=True)

data_insurance.info()

#Change Gender to dummy variable and drop the first dummy to prevent multicollinearity:
gender = pd.get_dummies(data_insurance['Gender'], drop_first=True)

# When the Male value is 1, it means the gender is male, and when the value is 0, the gender is female.
# We did not require both the Female and Gender variables in the dataset, as one can be used to predict the other.
data_insurance.drop('Gender',axis=1,inplace=True)
data_insurance = pd.concat([data_insurance,gender], axis=1)

data_insurance.head(10)

#Split the data into independent and dependent variables.
X = data_insurance.iloc[:,[0,6,10]] # Age, Annual_Premium and
X.head()

y = data_insurance.iloc[:, 9] # pay_policy
y.head()

"""#Transform the Numerical Variables: Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)
X

"""#Sebelum melatih model kita perlu memisahkan atribut dengan label. Selain itu, kita juga perlu membagi dataset menjadi data latih dan data uji."""

#Split the dataset into training and testing sets using the train_test_split function.
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""#Fitting the logistic regression model and predicting test results


"""

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression()
classifier.fit(X_train, y_train)

#Predict and get Accuray for the Test data
y_pred = classifier.predict(X_test)

#Let's create a Pandas DataFrame and compare the predicted and actual values
result = pd.DataFrame({'Actual' : y_test, 'Predicted' : y_pred})
result

print(classifier.coef_)

print(classifier.intercept_)

#evaluate model use predict_proba
print(classifier.predict_proba(X))

"""#Using confusion matrix From the Scikit-learn metrics module, we import confusion_matrix. The confusion matrix is the number of correct and incorrect predictions column-wise, showing the following values:



"""

#Making the Confusion Matrix
#True negatives(TN) in the upper-left position.
#False negatives(FN) in the lower-left position.
#False positives(FP) in the upper-right position.
#True positives(TP) in the lower-right position.
from sklearn.metrics import confusion_matrix
cf_matrix = confusion_matrix(y_test, y_pred)
cf_matrix

sns.heatmap(pd.DataFrame(cf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

#From the confusion_matrix, we have the following observations:
#100512 TN predictions: zeros predicted correctly.
#13821 FN predictions: ones wrongly predicted as zeros.
#0 FP predictions: zeros that were wrongly predicted as ones.
#0 TP predictions: ones predicted correctly.

# Also same result from sklearn accuracy_score
from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_pred)
#0.8791162656450894

#Creating a classification report for the model
target_names = ['will_NOT_pay_police', 'will_pay_policy']
print(classification_report(y_test, y_pred,target_names=target_names))

# Saving the model
filename = 'check_pay_police_or_not_pay.pkl'
pickle.dump(classifier,open(filename, 'wb'))